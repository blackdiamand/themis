---
import Base from "@layouts/base.astro";
import Grade from "@atoms/grade.astro";
import Math from "@atoms/math.astro";
import gradeCutoffs from "@data/grade_cutoffs.json";
import { Icon } from "astro-icon/components";

const api_base = import.meta.env.PGRST_URL;
console.log(api_base);

const scoreTypes = [
  {
    key: "brier",
    name: "Brier Score",
  },
  {
    key: "logarithmic",
    name: "Logarithmic Score",
  },
  {
    key: "spherical",
    name: "Spherical Score",
  },
  {
    key: "probability",
    name: "Probability Margin",
  },
];
---

<style>
  a {
    color: var(--color-lavender);
  }
</style>

<Base title="About">
  <div class="p-4 m-2">
    <h1 id="about" class="text-4xl font-bold">About</h1>
    <p class="my-2">
      <a href="https://predictionmetrics.org/" target="_blank"
        >PredictionMetrics.org</a
      > launched in 2025 to help people compare and evaluate prediction markets fairly.
      Our mission is to help the public make informed decisions about which markets
      to trust and how to interpret forecasting data. We believe in transparency,
      honest comparisons, and providing meaningful context.
    </p>
    <p class="my-2">
      The idea for this site started in July 2023 when we set out to create a
      calibration plot for Manifold, as they weren't publishing their own
      accuracy statistics at the time. What began as "Calibration City"
      eventually grew to include other platforms like Kalshi, Metaculus, and
      Polymarket. Thanks to grants from the Manifold Community Fund and EA
      Community Choice programs, we were able to expand our work. We added more
      markets, created new filters and charts, tracked accuracy metrics, and
      built guides for newcomers. However, we weren't comfortable sharing hard
      numerical accuracy scores or directly comparing platforms because they
      were fundamentally different from each other.
    </p>
    <p class="my-2">
      While our data was solid, it wasn't conveying the insights people
      expected. Calibration is very useful, but it can't ever tell the whole
      story. In January 2025, we initiated a complete overhaul. We started
      fresh, linking similar markets across platforms and finding directly
      comparable questions. We built a new website, less focused on
      experimentation and more focused on showing valuable results. We wanted to
      have something that actually answered questions like “How accurate are
      prediction markets?” and “Which platform is more accurate on the topics I
      care about?”
    </p>
    <p class="my-2">
      We're still growing - adding new platforms, curating interesting
      questions, and building new features. You can find all our source code
      under the on <a
        href="https://github.com/wasabipesto/themis"
        target="_blank"
      >
        GitHub project Themis</a
      >, complete with our open issues and roadmap. All our data is available
      through
      <a href="https://data.predictionmetrics.org" target="_blank">
        our PostgREST API</a
      >. We welcome collaboration and encourage others to use our data, with the
      hope that you'll share your findings with us.
    </p>

    <form
      id="newsletterForm"
      data-api-base={api_base}
      class="mt-6 m-2 p-4 bg-base-light text-crust rounded-md drop-shadow-sm grid grid-cols-1 md:grid-cols-2 gap-2"
    >
      <span class="mx-2">
        Interested in staying in touch? Learn about what's next via our mailing
        list.
      </span>
      <span class="mx-2 flex gap-2">
        <input
          type="email"
          id="emailNewsletterSignup"
          name="email"
          class="py-2 px-4 w-full h-full rounded-md border-1 border-crust"
          placeholder="rhanson@aol.com"
          required
        />
        <input
          type="submit"
          class="px-4 h-full rounded-md border-1 border-crust hover:bg-crust hover:text-base-light transition-colors duration-200"
          value="Subscribe"
        />
      </span>
    </form>
    <script>
      const form = document.getElementById("newsletterForm") as HTMLFormElement;
      form.addEventListener("submit", function (e: Event) {
        e.preventDefault();
        const api_base =
          form.dataset.apiBase || "https://data.predictionmetrics.org";
        const emailInput = document.getElementById(
          "emailNewsletterSignup",
        ) as HTMLInputElement;
        const email = emailInput.value;

        fetch(`${api_base}/newsletter_signups`, {
          method: "POST",
          headers: {
            "Content-Type": "application/json",
          },
          body: JSON.stringify({ email }),
        })
          .then((response) => {
            if (response.ok) {
              const button = form.querySelector(
                'input[type="submit"]',
              ) as HTMLInputElement;
              button.value = "Subscribed!";
              emailInput.value = "";
            } else {
              console.error(
                "Newsletter signup error:",
                response.status,
                response.statusText,
              );
            }
          })
          .catch((error) => {
            console.error("Newsletter signup error:", error);
          });
      });
    </script>
  </div>
  <hr class="my-2" />

  <div class="p-4 m-2">
    <h2 class="mb-4 text-3xl font-bold" id="faq">Frequently Asked Questions</h2>
    <div class="grid my-2">
      <div class="bg-crust rounded-md drop-shadow-sm p-4 m-2">
        <h3 class="text-xl font-bold" id="market-types">
          What market types do you support?
          <a href="#market-types">
            <Icon
              name="mdi:link-variant"
              class="inline-block mb-1 opacity-10 hover:opacity-100 transition-opacity duration-100"
            />
          </a>
        </h3>
        <p class="my-2">
          Broadly, we support all binary and multiple-choice markets on all
          supported platforms. There are a few asterisks around this, however.
        </p>
        <p class="my-2">
          For platforms like Kalshi and Polymarket where all markets are binary,
          the process is straightforward. Simple yes/no questions are extracted
          as-is, with the probability based on the price of the YES side. On
          these platforms, question groups are actually constructed out of
          binary markets (usually in the form of "Will team X win game Y?" or
          "Will metric X be greater than Y at time Z?") which makes extraction
          straightforward.
        </p>
        <p class="my-2">
          Manifold and Metaculus have a number of different market types, which
          they use for question groups and continuous spreads.
        </p>
        <ul class="my-2 ml-5 list-disc">
          <li>
            For dependent multiple-choice markets, where there are many
            potential outcomes but only one outcome can be selected (e.g. "Which
            film will win best picture at the 2025 Oscars?"). For those markets,
            we track the winner and use that option's probability over time as
            the market probability.
          </li>
          <li>
            On Manifold, dependent multiple-choice markets can actually resolve
            to multiple options as long as their resolution values sum to one.
            We do not currently evaluate markets that resolve in this way.
          </li>
          <li>
            For independent multiple choice markets, where any number of options
            can be selected, we decompose all options into their own binary
            markets. Each option has its own probability history and statistics.
            Currently only Manifold has this type, everyone else implements this
            concept as groups of binary markets.
          </li>
          <li>
            Both Manifold and Metaculus have a few versions of continuous
            markets, which predict a numeric value or date. For Manifold this
            includes "PseudoNumeric", "Number", "MultiNumeric", and "Date". For
            Metaculus this includes "Numeric" and "Date". We do not currently
            evaluate these markets, but we have plans to do so in the future.
          </li>
          <li>
            Finally, Metaculus has the special "Conditional" type. They are not
            currently supported but we have plans to implement this type in the
            future.
          </li>
        </ul>
        <p class="my-2">
          We used to assume that the implied probability of a market before the
          first trade was 50%, since that is how the probaility is often shown
          on each platform frontend. However, this caused problems if a
          significant amount of time elapsed between market creation and the
          first trade or if there were no trades whatsoever. Now, we consider
          the market to have no probability until the first trade. We also
          ignore any market that has zero trades for the same reason.
        </p>
        <p class="my-2">
          We do not evaluate non-market items from any platform, such as
          bounties, posts, or non-forecasting polls. Our downloader runs
          nightly, and notifies us of any new or unrecognized market types so we
          can implement them as quickly as possible.
        </p>
      </div>

      <div class="bg-crust rounded-md drop-shadow-sm p-4 m-2">
        <h3 class="text-xl font-bold" id="matching">
          How do you match markets together?
          <a href="#matching">
            <Icon
              name="mdi:link-variant"
              class="inline-block mb-1 opacity-10 hover:opacity-100 transition-opacity duration-100"
            />
          </a>
        </h3>
        <p class="my-2">
          When we first started working on the Calibration City site, we
          realized how different each prediction market platform was. The
          apples-to-oranges problem has reared its head many times and we were
          certainly not the first to realize this.
        </p>
        <p class="my-2">
          Our goal with the matching process is to find equivalent markets
          across platforms, usually by targeting one of the following
          situations.
        </p>
        <ul class="my-2 ml-5 list-disc">
          <li>
            There are some events that most prediction markets are already
            tracking, such as elections or sports tournaments. These are usually
            high-volume, popular markets, but can have subtle differences in
            resolution criteria.
          </li>
          <li>
            Some platforms will create "mirrors" of existing markets from other
            platforms, allowing users to see differences and arbitrate. These
            are nice because they will always resolve the same, but are usually
            limited to platforms that allow users to make their own markets.
          </li>
          <li>
            Occasionally, external groups will make predictions or encourage
            others to predict specific questions. Some of these, such as the ACX
            prediction content, have a wide range of valuable questions that
            share resolution criteria. Even better, some of these have awards
            that encourage good turnout.
          </li>
        </ul>
        <p class="my-2">
          After downloading items from each platform's API, we use a couple
          techniques to try to find these markets. We generate <a
            href="https://en.wikipedia.org/wiki/Word_embedding">embeddings</a
          > to find similar markets, then refine matches using tags, keywords, duration
          overlap, and other heuristics.
        </p>
        <p class="my-2">
          The final decision as to whether two markets are "equivalent" can be
          surprisingly difficult. For instance, there can be two markets that
          resolve on December 31st vs January 1st, or use two different news
          sources, or have any other number of slight variations that make them
          not 100% equivalent. In order to stay in the spirit of the concept, we
          allow grouping markets as long as these differences wouldn't have more
          than a 1% chance of changing the resolution.
        </p>
        <p class="my-2">
          All matches are picked and approved by real people. We do our best,
          but there may be some mistakes. <a href="#contact">Contact us</a> if you
          think there's an issue with a market link, or if you have a suggestion
          for additional market links.
        </p>
      </div>

      <div class="bg-crust rounded-md drop-shadow-sm p-4 m-2">
        <h3 class="text-xl font-bold" id="scores">
          How are the scores calculated?
          <a href="#scores">
            <Icon
              name="mdi:link-variant"
              class="inline-block mb-1 opacity-10 hover:opacity-100 transition-opacity duration-100"
            />
          </a>
        </h3>
        <p class="my-2">
          Currently we have two main types of scores: absolute and relative
          scores.
        </p>
        <h4 class="text-lg italic">Absolute Scores</h4>
        <p class="my-2">
          All absolute scores are calculated based on a criterion probability
          and scored using a scoring rule. The criterion probability is what we
          reference as the market's "prediction", and can be at a specific point
          in time like the midpoint or 30 days before resolution, or it could be
          an aggregation such as the time-weighted average probability.
        </p>
        <p class="my-2">
          The <a href="https://en.wikipedia.org/wiki/Brier_score">Brier score</a
          > is fairly intuitive, with better scores closer to zero and worse scores
          closer to one. Random guesses tend towards a score of 0.25 with superforecasters
          around 0.10. With any market's criterion probability <Math
            equation="p"
          /> and the market's resolution
          <Math equation="r" />, we can calculate the Brier score with:
        </p>
        <div class="text-center my-4">
          <Math
            equation={String.raw`
              \text{Brier Score} = \begin{cases}
              ~(p-1)^2 &\text{if } r = 1 \\
              ~p^2 &\text{if } r = 0 \\
              ~(p-r)^2 &\text{if } 0 \leq r \leq 1
              \end{cases}`}
          />
        </div>
        <p class="my-2">
          The <a
            href="https://en.wikipedia.org/wiki/Scoring_rule#Logarithmic_score"
            >logarithmic score</a
          > is another strictly proper scoring rule, but with better scores closer
          to zero and worse scores closer to negative infinity. Predictions far from
          the correct resolution are punished extremely hard with this scoring rule.
          With any market's criterion probability <Math equation="p" /> and resolution
          <Math equation="r" />, we can calculate the logarithmic score with:
        </p>
        <div class="text-center my-4">
          <Math
            equation={String.raw`
              \text{Logarithmic Score} = \begin{cases}
              ~ln(p)&\text{if } r = 1 \\
              ~ln(1-p) &\text{if } r = 0 \\
              ~r \cdot ln(p) + (1-r) \cdot ln(1-p) &\text{if } 0 \leq r \leq 1
              \end{cases}`}
          />
        </div>
        <p class="my-2">
          The <a
            href="https://en.wikipedia.org/wiki/Scoring_rule#Spherical_score"
            >spherical score</a
          > is a third strictly proper scoring rule. Better scores tend towards one
          but the worst possible score is only zero, but the vast majority of predictions
          will fall very high on this scale (between 0.99 and 1.0) so differentiation
          is difficult. With any market's criterion probability <Math
            equation="p"
          /> and resolution
          <Math equation="r" />, we can calculate the spherical score with:
        </p>
        <div class="text-center my-4">
          <Math
            equation={String.raw`
              \text{Spherical Score} = \begin{cases}
              ~\displaystyle\frac{p}{\sqrt{p^2+(1-p)^2}} &\text{if } r = 1 \\
              ~\displaystyle\frac{1-p}{\sqrt{p^2+(1-p)^2}} &\text{if } r = 0 \\
              ~\displaystyle\frac{r \cdot p+(1-r) \cdot (1-p)}{\sqrt{p^2+(1-p)^2}} &\text{if } 0 \leq r \leq 1
              \end{cases}`}
          />
        </div>
        <h4 class="text-lg italic">Relative Scores</h4>
        <p class="my-2">
          Relative scores are calculated based on the performance of the market
          relative to other markets. They provide a measure of how well the
          market has performed compared to its peers. These are only present for
          markets that are linked in a question, since they are scored against
          the other markets in that question.
        </p>
        <p class="my-2">
          We calculate a relative score with each scoring rule, which you can
          find on the individual question pages. The overall process is the
          exact same between each, with the only difference being the scoring
          rule used. Scoring rules where a lower score is better will be
          evaluated the same way for a relative score, so a lower relative Brier
          score is better while a higher relative logarithmic score is better.
        </p>
        <p class="my-2">
          The process to calculate relative scores for a group of markets starts
          by determining the scoring period. We choose to score groups for the
          duration where at least two markets are open. In some situations, we
          also override the start or end dates so that the scoring period does
          not include days where the outcome was already known.
        </p>
        <p class="my-2">
          For each day in the scoring period, we calculate each market's score
          using a scoring rule (Brier, log, etc.) and, from those, calculate the
          median score. We then subtract the median from each market's daily
          score and save it as the daily relative score.
        </p>
        <p class="my-2">
          Finally, we sum all of the daily relative scores for each market and
          divide that by the total number of days in the scoring period. Note
          that this is not a simple average! For markets that were not open for
          the entire scoring period, their sum is being divided by more days
          than they had values for. This means that a market that otherwise
          performed the same as another but was open for less time will have a
          relative score closer to zero. Also note that relative scores can be
          both positive and negative, since this is the difference from a median
          score.
        </p>
        <p class="my-2">
          One way to represent this score for each market would be:
        </p>
        <div class="text-center my-4">
          <Math
            equation={String.raw`\displaystyle\text{Relative Score} = \frac{\sum_{i=1}^{n} (s_i - m_i)}{n}`}
          />
        </div>
        <p class="my-2">
          Where <Math equation="s_i" /> is the market's score on day <Math
            equation="i"
          />, <Math equation="m_i" /> is the median score on day <Math
            equation="i"
          />, and <Math equation="n" /> is the number of days we're scoring.
        </p>
        <p class="my-2">
          You can learn more about relative scores at the following sources:
        </p>
        <ul class="list-disc my-2 px-5">
          <li>
            <a
              href="https://www.cultivatelabs.com/crowdsourced-forecasting-guide/what-are-relative-brier-scores-and-how-are-they-calculated"
              target="_blank"
            >
              Cultivate Labs: What are Relative Brier Scores and How are they
              Calculated?
            </a>
          </li>
          <li>
            <a href="https://www.gjopen.com/faq" target="_blank">
              Good Judgement Open: How are my forecasts scored for accuracy?
            </a>
          </li>
        </ul>
      </div>

      <div class="bg-crust rounded-md drop-shadow-sm p-4 m-2">
        <h3 class="text-xl font-bold" id="grades">
          How are the letter grades calculated?
          <a href="#grades">
            <Icon
              name="mdi:link-variant"
              class="inline-block mb-1 opacity-10 hover:opacity-100 transition-opacity duration-100"
            />
          </a>
        </h3>
        <p class="my-2">
          The letter grades are intended to be an easy-to-read, intuitive
          representation of how well the market has performed on a specific
          axis. Each score (e.g. Brier score at market midpoint, spherical score
          one month before close, etc.) has a corresponding letter grade, which
          is determined by comparing the score to a set of predefined
          thresholds.
        </p>
        <p class="my-2">The thresholds for absolute scores are:</p>
        <table class="table-fixed w-full">
          <thead>
            <tr>
              <th>Grade</th>
              {scoreTypes.map((st) => <th>{st.name}</th>)}
            </tr>
          </thead>
          <tbody>
            {
              gradeCutoffs.map((g) => (
                <tr class="odd:bg-selection/10 text-center">
                  <td class="py-1 px-2">
                    <div class="w-30 mx-auto">
                      <Grade grade={g.grade} />
                    </div>
                  </td>
                  {g.scores.map((score) => (
                    <td class="font-mono">
                      {score.min.toFixed(4)} to {score.max.toFixed(4)}
                    </td>
                  ))}
                </tr>
              ))
            }
          </tbody>
        </table>
        <div class="my-4"></div>
        <p class="my-2">
          The thresholds for relative scores are a little different. The
          relative scoring algorithm we use results in a lot of scores very
          close to zero with a sharp dropoff and roughly-symmetrical curve on
          either side. We calculate our grade cutoffs so that C+ is centered at
          zero, with widths based on the deviations of the scores.
        </p>
        <p class="my-2">
          The thresholds for relative scores can be <a
            href="https://github.com/wasabipesto/themis/blob/main/grader/src/scores/lettergrade.rs"
            class="text-lavender"
          >
            found on GitHub
          </a>
          for now while we continue to add questions and tweak the grades in response.
        </p>
      </div>
    </div>

    <div class="bg-crust rounded-md drop-shadow-sm p-4 m-2">
      <h3 class="text-xl font-bold" id="support">
        How can I support development of this site?
        <a href="#support">
          <Icon
            name="mdi:link-variant"
            class="inline-block mb-1 opacity-10 hover:opacity-100 transition-opacity duration-100"
          />
        </a>
      </h3>
      <p class="my-2">
        If you find this site useful, please share it with others! We believe
        prediction markets are valuable, but only if their accuracy is verified
        and understood. We believe prediction markets should be evaluated
        rigorously and publicly, showing both their strengths and weaknesses, in
        order to earn credibility.
      </p>
      <p class="my-2">
        Please also share your feedback about the site with us. Currently our
        focus is on improving the site, making it more intuitive to use while
        also adding new features that give valuable insights. We're specifically
        interested in:
      </p>
      <ul class="list-disc ml-5">
        <li>
          Was the site easy to navigate? Did it make sense how to find the
          information you wanted?
        </li>
        <li>
          Did any of the explanations make sense? Was there anything confusing,
          contradictory, or misleading? Were there any claims that felt weak or
          unsupported?
        </li>
        <li>
          Is the site missing a market platform or category that you're
          interested in? Any topic that isn't covered in our questions?
        </li>
        <li>
          Does it feel like the site is missing a certain metric or statistic?
          Is there anything else you feel we could do with this data?
        </li>
        <li>
          Do you have your own database of markets for arbitrage that you're
          willing to share?
        </li>
      </ul>
      <p class="my-2">
        You can shoot us an email at <a
          href="mailto:contact@predictionmetrics.org"
          >contact@&#8203;predictionmetrics.org</a
        > or use the form below to submit feedback.
      </p>
    </div>
  </div>
  <hr class="my-2" />

  <div class="p-4 m-2">
    <h2 class="mb-4 text-3xl font-bold" id="contact">
      Contact
      <a href="#contact">
        <Icon
          name="mdi:link-variant"
          class="h-5 inline-block mb-1 opacity-10 hover:opacity-100 transition-opacity duration-100"
        />
      </a>
    </h2>
    <div class="bg-crust rounded-md drop-shadow-sm p-4 m-2">
      <h3 class="text-xl font-bold" id="matching">Getting in Touch</h3>
      <p class="my-2">
        Having an issue with the site? See a bug or a typo? Found a set of
        markets that aren't covered here? Do you need help accessing the data
        for a research project? Here's how you can contact us:
      </p>
      <ul class="list-disc my-2 px-6">
        <li>
          For issues with the site, backend API, data downloaders or extractors,
          or anying else to do with code,
          <a
            href="https://github.com/wasabipesto/themis/issues/new"
            class="underline"
            target="_blank"
          >
            please submit an issue on GitHub</a
          >. Also please submit an issue if you have ideas for new features or
          improvements.
        </li>
        <li>
          If you're interested in contributing to the project, please check out
          the <a
            href="https://github.com/wasabipesto/themis/labels/help%20wanted"
            class="underline"
            target="_blank">Help Wanted</a
          > tag on GitHub Issues. There are usually some features I'm looking to
          implement or problems that need solving. If you have an idea for an improvement
          not already tracked, please get in touch first so we can discuss it before
          spending time on a pull request.
        </li>
        <li>
          For questions about the site or assistance with the data, or for any
          other inquiry, feel free to reach out to us via email at
          <a href="mailto:contact@predictionmetrics.org" class="underline"
            >contact@&#8203;predictionmetrics.org</a
          >. This is likely the fastest way to get in touch with us.
        </li>
      </ul>
      <p class="my-2">And finally, here's a handy form for anything else:</p>

      <form id="feedbackForm" data-api-base={api_base} class="m-2">
        <div class="mx-auto">
          <div class="mb-4">
            <label for="email" class="block text-sm font-medium text-text mb-1">
              Contact Email
            </label>
            <input
              type="text"
              id="feedbackEmail"
              name="email"
              required
              class="w-full px-3 py-2 rounded-md shadow-sm border border-text focus:border-blue focus:outline-none"
              placeholder="rhanson@aol.com"
            />
          </div>
          <div class="mb-4">
            <label
              for="feedbackType"
              class="block text-sm font-medium text-text mb-1"
            >
              Feedback Type
            </label>
            <select
              id="feedbackType"
              name="type"
              required
              class="w-full px-3 py-2 rounded-md shadow-sm border border-text focus:border-blue focus:outline-none"
            >
              <option value="" disabled>Select a Feedback Type</option>
              <option value="site-issue">Issues with the Site</option>
              <option value="bug">Bug, Error, or Security Issue</option>
              <option value="market-link">Suggest a New Market Link</option>
              <option value="general">General Inquiry or Data Requests</option>
              <option value="compliment">Compliment or Thanks</option>
              <option value="other">Something Else</option>
            </select>
          </div>
          <div class="mb-4">
            <label
              for="feedbackContent"
              class="block text-sm font-medium text-text mb-1"
            >
              Feedback
            </label>
            <textarea
              id="feedbackContent"
              name="content"
              rows="7"
              required
              class="w-full px-3 py-2 rounded-md shadow-sm border border-text focus:border-blue focus:outline-none"
              placeholder="Description of your issue, links to your suggested markets, or any other questions you have."
            ></textarea>
          </div>
          <div class="flex justify-end gap-4">
            <div class="">
              <label for="feedbackNewsletterSignup" class="text-sm px-1">
                Also sign me up for the mailing list
              </label>
              <input
                id="feedbackNewsletterSignup"
                name="newsletterSignup"
                type="checkbox"
                value="newsletter"
                class="px-4"
              />
            </div>
            <div class="">
              <input
                type="submit"
                class="px-4 py-1 text-crust rounded-md bg-base-light hover:bg-blue transition-colors duration-200"
                value="Submit"
              />
            </div>
          </div>
        </div>
      </form>
      <script>
        const form = document.getElementById("feedbackForm") as HTMLFormElement;
        form.addEventListener("submit", function (e: Event) {
          e.preventDefault();
          const api_base =
            form.dataset.apiBase || "https://data.predictionmetrics.org";
          const email = (
            document.getElementById("feedbackEmail") as HTMLInputElement
          ).value;
          const feedback_type = (
            document.getElementById("feedbackType") as HTMLInputElement
          ).value;
          const feedback = (
            document.getElementById("feedbackContent") as HTMLInputElement
          ).value;
          const signup = (
            document.getElementById(
              "feedbackNewsletterSignup",
            ) as HTMLInputElement
          ).checked;

          fetch(`${api_base}/general_feedback`, {
            method: "POST",
            headers: {
              "Content-Type": "application/json",
            },
            body: JSON.stringify({ email, feedback_type, feedback }),
          })
            .then((response) => {
              if (response.ok) {
                const button = form.querySelector(
                  'input[type="submit"]',
                ) as HTMLInputElement;
                button.value = "Submitted!";
              } else {
                console.error(
                  "Feedback submit error:",
                  response.status,
                  response.statusText,
                );
              }
            })
            .catch((error) => {
              console.error("Feedback submit error:", error);
            });

          if (signup) {
            fetch(`${api_base}/newsletter_signups`, {
              method: "POST",
              headers: {
                "Content-Type": "application/json",
              },
              body: JSON.stringify({ email }),
            })
              .then((response) => {
                if (!response.ok) {
                  console.error(
                    "Newsletter signup error:",
                    response.status,
                    response.statusText,
                  );
                }
              })
              .catch((error) => {
                console.error("Newsletter signup error:", error);
              });
          }
        });
      </script>
    </div>
  </div>
  <hr class="my-2" />

  <div class="p-4 m-2">
    <h2 class="mb-4 text-3xl font-bold" id="resources">
      Links & Resources
      <a href="#resources">
        <Icon
          name="mdi:link-variant"
          class="h-5 inline-block mb-1 opacity-10 hover:opacity-100 transition-opacity duration-100"
        />
      </a>
    </h2>

    <div class="grid grid-cols-1 md:grid-cols-2 my-2">
      <div class="bg-crust rounded-md drop-shadow-sm p-4 m-2">
        <h3 class="text-xl font-bold">Prediction Market Explanations</h3>
        <p class="my-1 italic">
          <a
            href="https://www.astralcodexten.com/p/prediction-market-faq"
            target="_blank"
          >
            Astral Codex Ten: Prediction Market FAQ
          </a>
        </p>
        <p class="my-1">
          Scott Alexander gives a summary of what prediction markets are, their
          fundamental qualities, and common objections. It's excellent and super
          easy to read - if you read anything from this list, it should be this
          one.
        </p>
        <div class="my-2"></div>
        <p class="my-1 italic">
          <a
            href="https://en.wikipedia.org/wiki/Prediction_market"
            target="_blank"
          >
            Wikipedia: Prediction market
          </a>
        </p>
        <p class="my-1">
          The obligatory Wikipedia page on the topic. It has a good overview and
          timeline of the recent history, but not much else.
        </p>
        <div class="my-2"></div>
        <p class="my-1 italic">
          <a
            href="https://outsidetheasylum.blog/prediction-markets-are-not-polls/"
            target="_blank"
          >
            Prediction Markets are not Polls
          </a>
        </p>
        <p class="my-1">
          A common refrain to prediction markets is that they're "just polls of
          random people on the internet". Isaac King puts together a great
          rebuttal with examples as to why this is not the case.
        </p>
        <div class="my-2"></div>
        <p class="my-1 italic">
          <a
            href="https://thezvi.wordpress.com/2018/07/26/prediction-markets-when-do-they-work/"
            target="_blank"
          >
            Prediction Markets: When Do They Work?
          </a>
        </p>
        <p class="my-1">
          In an older post (from 2018), Zvi discusses some situations where
          prediction markets thrive, and some where they don't. There are many
          more markets today, but I believe the basis of this post still holds.
        </p>
      </div>

      <div class="bg-crust rounded-md drop-shadow-sm p-4 m-2">
        <h3 class="text-xl font-bold">
          Previous Aggregation & Comparison Research
        </h3>
        <p class="my-1 italic">
          <a
            href="https://firstsigma.substack.com/p/midterm-elections-forecast-comparison-analysis"
            target="_blank"
          >
            First Sigma: What can we learn from scoring different election
            forecasts?
          </a>
        </p>
        <p class="my-1">
          Jack compares head-to-head performance between Metaculus, 538,
          Manifold, Polymarket, EBO, and PredictIt on the US 2022 midterm
          elections. Metaculus and 538 took the lead but with a small sample
          size.
        </p>
        <div class="my-2"></div>
        <p class="my-1 italic">
          <a
            href="https://forum.effectivealtruism.org/posts/PGqu4MD3AKHun7kaF/predictive-performance-on-metaculus-vs-manifold-markets"
            target="_blank"
          >
            EA Forum: Predictive Performance on Metaculus vs. Manifold Markets
          </a>
        </p>
        <p class="my-1">
          A direct comparison of 64 binary markets mirrored between Manifold and
          Metaculus. Metaculus had a better score on 75% of the questions.
        </p>
        <div class="my-2"></div>
        <p class="my-1 italic">
          <a
            href="https://projects.jhkforecasts.com/forecast-history/index.html"
            target="_blank"
          >
            JHK Forecasts: Forecast Database
          </a>
        </p>
        <p class="my-1">
          Jack Kersting (a different Jack) assembled an impressive list of US
          election forecasts across dozens of predictors from 2016 to 2024.
          While this isn't comparing prediction markets, it's still a good
          example of prediction metrics.
        </p>
      </div>

      <div class="bg-crust rounded-md drop-shadow-sm p-4 m-2">
        <h3 class="text-xl font-bold">Platform Self-Scoring</h3>
        <p class="my-1">
          Many platforms will score themselves and publish their results, or
          users will create dashboards similar to this site with the API or
          blockchain data. We took a lot of inspiration from these sites when
          creating our standardized scoring format and inspiration for our <a
            href="charts">charts</a
          >.
        </p>
        <ul class="list-disc my-2 px-6">
          <li>
            <a
              href="https://www.metaculus.com/questions/track-record/"
              target="_blank"
            >
              Metaculus: Track Record
            </a>
          </li>
          <li>
            <a
              href="https://dune.com/alexmccullough/how-accurate-is-polymarket"
              target="_blank"
            >
              Polymarket Historical Accuracy and Bias
            </a>
          </li>
          <li>
            <a href="https://manifold.markets/calibration" target="_blank">
              Manifold: Calibration
            </a>
          </li>
          <li>
            <a
              href="https://electionbettingodds.com/TrackRecord.html"
              target="_blank"
            >
              Election Betting Odds: Track Record
            </a>
          </li>
          <li>
            <a
              href="https://web.archive.org/web/20250306130304/https://projects.fivethirtyeight.com/checking-our-work/"
              target="_blank"
            >
              538: How Good Are FiveThirtyEight Forecasts? (Archived)
            </a>
          </li>
        </ul>
      </div>

      <div class="bg-crust rounded-md drop-shadow-sm p-4 m-2">
        <h3 class="text-xl font-bold">Scoring Rules</h3>
        <p class="my-1 italic">
          <a href="https://en.wikipedia.org/wiki/Scoring_rule" target="_blank">
            Wikipedia: Scoring Rule
          </a>
        </p>
        <p class="my-1">
          The Wikipedia page on scoring rules. It was a great starting point for
          our research due to covering many different score types.
        </p>
        <div class="my-2"></div>
        <p class="my-1 italic">
          <a
            href="https://www.cultivatelabs.com/crowdsourced-forecasting-guide/what-are-relative-brier-scores-and-how-are-they-calculated"
            target="_blank"
          >
            Cultivate Labs: Relative Brier Scores
          </a>
        </p>
        <p class="my-1">
          This post from Cultivate Labs describing their relative scoring system
          is really the basis for this site. It describes the method of creating
          relative scores based on the daily mean score, with the added twist of
          penalizing forecasters that start predicting later.
        </p>
        <div class="my-2"></div>
        <p class="my-1 italic">
          <a href="https://erischel.com/againstcalibration/" target="_blank">
            Eigil Fjeldgren Rischel: Against calibration
          </a>
        </p>
        <p class="my-1">
          A good summation of calibration versus accuracy, mainly that
          calibration can be applied more broadly but is less meaningful. This
          is exactly why we switched focus on this site away from calibration!
        </p>
      </div>

      <div class="bg-crust rounded-md drop-shadow-sm p-4 m-2">
        <h3 class="text-xl font-bold">Scientific Articles</h3>
        <p class="my-1 italic">
          <a
            href="https://doi.org/10.1016/j.ijforecast.2008.03.007"
            target="_blank"
          >
            Prediction market accuracy in the long run
          </a>
        </p>
        <p class="my-1">
          A comparison of the performance of Iowa Electronic Markets (a small
          academic platform) versus contemporary polls. Between 1988 to 2004,
          the markets outperformed polls 74% of the time.
        </p>
        <div class="my-2"></div>
        <p class="my-1 italic">
          <a href="https://doi.org/10.48550/arXiv.2503.03312" target="_blank">
            How manipulable are prediction markets?
          </a>
        </p>
        <p class="my-1">
          A team attempts to manipulate 817 random markets on Manifold in early
          2024 and finds that the manipulations were somewhat reversed after 7
          days, moreso after 30 days.
        </p>
      </div>

      <div class="bg-crust rounded-md drop-shadow-sm p-4 m-2">
        <h3 class="text-xl font-bold">Miscellaneous</h3>
        <p class="my-1 italic">
          <a href="https://metaforecast.org/" target="_blank"> Metaforecast </a>
        </p>
        <p class="my-1">
          Metaforecast was created by Nuño Sempere (and now maintained by
          <a href="https://quantifieduncertainty.org/">QURI</a>) to be a search
          engine for prediction markets from over a dozen platforms. One search
          bar to find open predictions from basically anywhere.
        </p>
        <div class="my-2"></div>
        <p class="my-1 italic">
          <a
            href="https://saul-munn.notion.site/Map-of-the-Prediction-Market-Forecasting-Ecosystem-4ffddd0f10d64fdb92235b374ec5e3f1"
            target="_blank"
          >
            Saul Munn: Prediction Market Map
          </a>
        </p>
        <p class="my-1">
          If you're interested in exploring everything there is to know about
          prediction markets, Saul keeps a categorized list of resources on
          Notion.
        </p>
      </div>
    </div>
  </div>
</Base>
